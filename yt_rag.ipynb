{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "tIQ-GWfJNIF7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8444a3a1-bccd-40b9-f41a-ad0f2d035cb7",
        "collapsed": true
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33mWARNING: gradio 5.31.0 does not provide the extra 'themes'\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -q langchain langchain-core langchain-huggingface youtube-transcript-api langchain-community faiss-cpu tiktoken gradio"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_huggingface import HuggingFacePipeline, HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from youtube_transcript_api import YouTubeTranscriptApi, TranscriptsDisabled\n",
        "from langchain_core.prompts import PromptTemplate\n",
        "# from langchain.retrievers.contextual_compression import ContextualCompressionRetriever\n",
        "# from langchain.retrievers.document_compressors import LLMChainExtractor\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel\n",
        "# from langchain import LlamaCpp\n",
        "import re\n",
        "import gradio as gr"
      ],
      "metadata": {
        "id": "cE318qTVOTRp"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing -> a)document ingestion"
      ],
      "metadata": {
        "id": "aAKjhTr3QdK2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_video_id(url):\n",
        "    # Regular expression pattern for common YouTube URL formats\n",
        "    pattern = r\"(?:v=|\\/)([0-9A-Za-z_-]{11}).*\"\n",
        "    match = re.search(pattern, url)\n",
        "    return match.group(1) if match else None\n",
        "\n",
        "def extract_transcript(url):\n",
        "    video_id = extract_video_id(url)\n",
        "    if not video_id:\n",
        "        return \"âŒ Invalid YouTube URL.\"\n",
        "    try:\n",
        "    # If you donâ€™t care which language, this returns the â€œbestâ€ one\n",
        "        transcript_list = YouTubeTranscriptApi.get_transcript(video_id, languages=[\"en\"])\n",
        "\n",
        "    # Flatten it to plain text\n",
        "        transcript = \" \".join(chunk[\"text\"] for chunk in transcript_list)\n",
        "        return transcript\n",
        "\n",
        "    except TranscriptsDisabled:\n",
        "        return \"No captions available for this video.\""
      ],
      "metadata": {
        "id": "22djIrfeBbSY"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Indexing -> b)text splitting"
      ],
      "metadata": {
        "id": "8C_fB8rJRF1c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=1000,\n",
        "    chunk_overlap=200,\n",
        ")"
      ],
      "metadata": {
        "id": "XQcdh3HrQ6dO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Indexing -> c)Embedding generation and d)storing in vector store"
      ],
      "metadata": {
        "id": "nYp6C9_7R7hS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the path to the pre-trained model you want to use\n",
        "modelPath = \"sentence-transformers/all-MiniLM-l6-v2\"\n",
        "\n",
        "# Create a dictionary with encoding options, specifically setting 'normalize_embeddings' to False\n",
        "encode_kwargs = {'normalize_embeddings': True}\n",
        "\n",
        "# Initialize an instance of HuggingFaceEmbeddings with the specified parameters\n",
        "embeddings = HuggingFaceEmbeddings(\n",
        "    model_name=modelPath,\n",
        "    encode_kwargs=encode_kwargs\n",
        ")"
      ],
      "metadata": {
        "id": "CDE_pNGQRZFM"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# vector_store.index_to_docstore_id"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2hPmhBVDT2QF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Retrival"
      ],
      "metadata": {
        "id": "Iy1BLckZU7Dk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# base_retriever = vector_store.as_retriever(\n",
        "#     search_type=\"mmr\",\n",
        "#     search_kwargs={\"k\": 3,\"lambda_mult\": 0.5}\n",
        "# )"
      ],
      "metadata": {
        "id": "rCUijv2PT2Nw"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Augmentation"
      ],
      "metadata": {
        "id": "C9Ux_pUcuLN9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm = HuggingFacePipeline.from_model_id(\n",
        "    model_id='TinyLlama/TinyLlama-1.1B-Chat-v1.0',\n",
        "    task='text-generation',\n",
        "    pipeline_kwargs={\n",
        "        \"repetition_penalty\": 1.2,\n",
        "        \"max_new_tokens\":600\n",
        "    }\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08vmI0ArnqMZ",
        "outputId": "e008a578-1988-415b-ae7d-356da0568363"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cuda:0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "prompt = PromptTemplate(\n",
        "    template = \"\"\"You are an assistant for question-answering tasks.\n",
        "    Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use four sentences maximum and keep the answer concise.\n",
        "Context: {context}\n",
        "Question: {question}\n",
        "Answer:\"\"\",\n",
        "    input_variables=[\"context\", \"question\"]\n",
        ")\n"
      ],
      "metadata": {
        "id": "mbWmigYqnqI_"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_context(context):\n",
        "  return \"\\n\\n\".join([doc.page_content for doc in context])"
      ],
      "metadata": {
        "id": "XNOBpV3SwG_Q"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_answer(llmresponse):\n",
        "  qa = llmresponse.split(\"Question:\")[-1].strip()\n",
        "  ans = qa.split(\"Answer:\")[-1].strip() if \"Answer:\" in qa else qa.split(\"?\\n\")[-1].strip()\n",
        "  return ans"
      ],
      "metadata": {
        "id": "iTveVMax4vnN"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Generation"
      ],
      "metadata": {
        "id": "wi2vOn7a8UkA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # fetch transcript\n",
        "# transcript = extract_transcript(\"https://www.youtube.com/watch?v=p0FERNkpyHE\")\n",
        "\n",
        "# #create chunks\n",
        "# chunks = splitter.create_documents([transcript])\n",
        "\n",
        "# # vectorize and store\n",
        "# vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "\n",
        "# # retrieval\n",
        "# base_retriever = vector_store.as_retriever(\n",
        "#     search_type=\"mmr\",\n",
        "#     search_kwargs={\"k\": 3,\"lambda_mult\": 0.5}\n",
        "# )\n",
        "\n",
        "# # creating a chain\n",
        "# parallel_chain = RunnableParallel(\n",
        "#     {\n",
        "#         \"context\": base_retriever|RunnableLambda(format_context),\n",
        "#         \"question\": RunnablePassthrough()\n",
        "#     }\n",
        "# )\n",
        "# main_chain = parallel_chain | prompt | llm | RunnableLambda(get_answer)"
      ],
      "metadata": {
        "id": "skhlHLeM1-Yx"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate(url, question):\n",
        "    transcript = extract_transcript(url)\n",
        "    chunks = splitter.create_documents([transcript])\n",
        "    vector_store = FAISS.from_documents(chunks, embeddings)\n",
        "    base_retriever = vector_store.as_retriever(\n",
        "        search_type=\"mmr\",\n",
        "        search_kwargs={\"k\": 3,\"lambda_mult\": 0.5}\n",
        "    )\n",
        "    parallel_chain = RunnableParallel(\n",
        "        {\n",
        "            \"context\": base_retriever|RunnableLambda(format_context),\n",
        "            \"question\": RunnablePassthrough()\n",
        "        }\n",
        "    )\n",
        "    main_chain = parallel_chain | prompt | llm | RunnableLambda(get_answer)\n",
        "    return main_chain.invoke(question)"
      ],
      "metadata": {
        "id": "cA3tKoq45Cge"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# generate(url =\"https://www.youtube.com/watch?v=p0FERNkpyHE\" ,question =\"gice a brief info about what is discussed in this? \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "DcmKHGi75Xwg",
        "outputId": "b2d5d731-2383-47e8-f9e2-4e4cfc964061"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'This is a gentic rag. The way it works compared to traditional Rag is with a set of genetic elements represented by their embeddings. These embeddings represent the content of each element. Then together they form a graph of relationships between elements, and the edges in the graph correspond to the relationships between them. Intraday volatility trading strategies, and now this graph represents three dimensions -- element type (like text), positional attributes, such as relevance, and temporal characteristics, such as time since publication and relative age. By working with these interconnected embeddings, we can learn patterns, clusters, and connections across vast amounts of data. With knowledge graphs as core components of the system, users can easily integrate and visualize knowledge from multiple sources, and the system itself helps understand and make relevant decisions.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "with gr.Blocks(theme = gr.themes.Citrus()) as demo:\n",
        "    gr.Markdown(\"## ðŸŽ¥ YouTube QA with TinyLLaMA\")\n",
        "\n",
        "    url_input = gr.Textbox(label=\"Enter YouTube URL\")\n",
        "    question_input = gr.Textbox(label=\"Your Question\")\n",
        "    output = gr.Textbox(label=\"Answer\")\n",
        "\n",
        "    btn = gr.Button(\"Get Answer\")\n",
        "\n",
        "    btn.click(fn=generate, inputs=[url_input, question_input], outputs=output)\n",
        "\n",
        "demo.launch(share = True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 650
        },
        "id": "WTr40jP18zlK",
        "outputId": "f864cca5-6d90-4da6-c9db-abed9092ab47"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted a Jupyter notebook. For the Gradio app to work, sharing must be enabled. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://5f07d332cda19690b2.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://5f07d332cda19690b2.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "efsa0gs583Tv"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}